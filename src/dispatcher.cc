#include <cstdio>
#include <cstdlib>
#include <ctime>
#include <cstring>
#include <iostream>
#include <string>
#include <vector>

#include <opencv2/opencv.hpp>
//#include <Python.h>
#include "sugar/sugar.h"
#include "extractor.h"
//#include "pywrapper/dbconn.h"

using namespace cv;
using std::string;
using std::vector;
using std::cout;
using std::endl;

const char *kDirPrefix = "/media/reimondo/HDD/Workspace/Projects/gee/";
const int kCount = 10;
const int kBufferSize = 100;

// global variables
Mat g_frame;      // current frame
Mat g_frame_before;   // reserved frame
Mat g_fg_mask_MOG2;   // fg mask fg mask generated by MOG2 method
Ptr<BackgroundSubtractor> g_pMOG2;    // MOG2 Background subtractor
int g_keyboard;

void Dispatcher();
// $start debug
void Test();
//void PyTest();
// $end debug

int main()
{
     Dispatcher();
    // Test();
    //PyTest();

    exit(0);
}

// Dispatcher.
//
void Dispatcher()
{
    char video_stream_addr[kBufferSize];
    // sprintf(video_stream_addr, "%s%s", kDirPrefix, "cam.sdp");
    sprintf(video_stream_addr, "%s%s", kDirPrefix, "example/videos/WP_20151002_09_40_51_Pro_lq.mp4");

    // create video stream capture
    VideoCapture cap(video_stream_addr);
    if (!cap.isOpened()) {
        LogError("Fail to open video stream.");
        exit(1);
    }

    // init extractor
    Extractor extractor;

    char video_saving_addr[kBufferSize];
    sprintf(video_saving_addr, "%s%s", kDirPrefix, "out/videos/");
    // create video stream writer
    VideoWriter writer;
    writer.open("1-raw.h264", CV_FOURCC('X', '2', '6', '4'), cap.get(CV_CAP_PROP_FPS),
                Size(cap.get(CV_CAP_PROP_FRAME_WIDTH), cap.get(CV_CAP_PROP_FRAME_HEIGHT)));

    // init timestamp
    double timestamp_before = cap.get(CV_CAP_PROP_POS_MSEC);
    double timestamp_after = cap.get(CV_CAP_PROP_POS_MSEC);

    // start the first writer
    /*
    char video_name_1st[kBufferSize];
    sprintf(video_name_1st, "%s%.0lf-%.0lf.%s",
            video_saving_addr, timestamp_after, timestamp_after+60000, "h264");

    Size framesize(cap.get(CV_CAP_PROP_FRAME_WIDTH),
                   cap.get(CV_CAP_PROP_FRAME_HEIGHT));
    writer.open(video_name_1st, CV_FOURCC('X', '2', '6', '4'),
                cap.get(CV_CAP_PROP_FPS), framesize);
    if (!writer.isOpened()) {
        LogError("Fail to open the first saving file!");
        exit(1);
    }
    */

    // create Background Subtractor objects
    // g_pMOG2 = createBackgroundSubtractorMOG2(); // MOG2 approach

    while ((char)g_keyboard != 'q' && (char)g_keyboard != 27) {
        // read the current frame
        if (!cap.read(g_frame)) {
            LogError("Unable to read next frame.");
            LogError("Exiting...");
            exit(1);
        }

        // Stage 1 - save, 1min per piece.
        // update the second timestamp
        /*
        timestamp_after = cap.get(CV_CAP_PROP_POS_MSEC);
        if ((timestamp_after - timestamp_before) >= 60000) {    // 1min = 60000ms
            // release old video writer
            writer.release();
            // create new filename
            char video_name[kBufferSize];
            sprintf(video_name, "%s%.0lf-%.0lf.%s",
                    video_saving_addr, timestamp_after, timestamp_after+60000, "h264");

            Size framesize(cap.get(CV_CAP_PROP_FRAME_WIDTH),
                           cap.get(CV_CAP_PROP_FRAME_HEIGHT));
            // create a new video writer
            writer.open(video_name, CV_FOURCC('X', '2', '6', '4'),
                        cap.get(CV_CAP_PROP_FPS), framesize);
            if (!writer.isOpened()) {
                LogError("Fail to open saving file!");
                exit(0);
            }
            writer << g_frame;
            // update the first timestamp
            timestamp_before = cap.get(CV_CAP_PROP_POS_MSEC);
        } else {
            // continue to write
            writer << g_frame;
        }
        */

        // Stage 2 - extract key frame.
        extractor.handler(g_frame);
        // init frame_before and save the fisrt frame
        /*
        if (g_frame_before.empty()) {
            g_frame_before = g_frame.clone();

            char keyframe_name[kBufferSize];
            sprintf(keyframe_name, "%s%s%.0lf.%s",
                    pic_saving_addr, "kf_", cap.get(CV_CAP_PROP_POS_MSEC), "jpeg");
            vector<int> c_params;
            c_params.push_back(CV_IMWRITE_JPEG_QUALITY);
            imwrite(keyframe_name, g_frame, c_params);
        }

        if (HistDiff(g_frame_before, g_frame)) {
            char keyframe_name[kBufferSize];
            sprintf(keyframe_name, "%s%s%.0lf.%s",
                    pic_saving_addr, "kf_", cap.get(CV_CAP_PROP_POS_MSEC), "jpeg");
            vector<int> c_params;
            c_params.push_back(CV_IMWRITE_JPEG_QUALITY);
            imwrite(keyframe_name, g_frame, c_params);

            // update old frame
            g_frame_before.release();
            g_frame_before = g_frame.clone();
        }
        // show key frame change
        imshow("Key Frame", g_frame_before);
        */

        // Stage 3 - motion detect and output.
        // update the backgroud model
        // g_pMOG2->apply(g_frame, g_fg_mask_MOG2);
        // get the frame number and write in on the current frame
        rectangle(g_frame, Point(10, 2), Point(100, 20),
                  Scalar(255, 255, 255), -1);
        putText(g_frame, NumberToString<float>(cap.get(CAP_PROP_POS_FRAMES)),
                Point(15, 15), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 0, 0));

        // find the boundary
        /*
        vector<vector<Point> > contours;
        vector<Vec4i> hierarchy;
        findContours(g_fg_mask_MOG2.clone(), contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE);
        for (int i = 0; i < contours.size(); i++) {
            if (contourArea(contours[i]) < 500)
                continue;

            Rect rect(boundingRect(contours[i]));
            rectangle(g_frame, rect, Scalar(0, 255, 0), 2);
        }
        */

        // show the current frame and the fg masks
        // writer << g_frame;
        imshow("Frame", g_frame);
        // threshold(g_fg_mask_MOG2, g_fg_mask_MOG2, 25, 255, THRESH_BINARY);
        // imshow("FG Mask MOG 2", g_fg_mask_MOG2);
        // get the input from the keyboard
        g_keyboard = waitKey(1);
    }
}

void Test()
{
    char example_addr[kBufferSize];
    sprintf(example_addr, "%s%s", kDirPrefix, "example/");

    char test_pics_addr[kBufferSize], test_videos_addr[kBufferSize];
    sprintf(test_pics_addr, "%s%s", kDirPrefix, "pictures/");
    sprintf(test_videos_addr, "%s%s", kDirPrefix, "videos/");

    char pic1[kBufferSize];
    char pic2[kBufferSize];
    sprintf(pic1, "%s%s", test_pics_addr, "0.jpg");
    sprintf(pic2, "%s%s", test_pics_addr, "9.jpg");
    Mat frame_t1 = imread(pic1);
    Mat frame_t2 = imread(pic2);
    imshow("-_-", frame_t1);
    imshow("-_-", frame_t2);
    FrameDiff(frame_t1, frame_t2);
}

//void PyTest()
//{
//    Py_Initialize();
//    initdbconn();
//    py_print("This is c++");
//    // init_table();
//    has_table("test");
//    Py_Finalize();
//}
